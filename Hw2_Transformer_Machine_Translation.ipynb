{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shubhamd13/NLP/blob/main/Hw2_Transformer_Machine_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "# put your student name here, you will need to train the model that prints out your name in each loss\n",
        "# without the name, you will not be able to get points in train part\n",
        "STUDENT_NAME = \"Shubham Derhgawen\""
      ],
      "metadata": {
        "id": "jbYfCX1-csCu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preliminary\n",
        "Credit: https://nlp.seas.harvard.edu/annotated-transformer/\n",
        "\n",
        "Download required packages, Imports libraries, sets random seeds."
      ],
      "metadata": {
        "id": "nwdhro5z9J_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torchaudio torchvision\n",
        "!pip install --force-reinstall torchtext==0.16.2\n",
        "!pip install portalocker>=2.0.0\n",
        "!python -m spacy download en_core_web_sm\n",
        "!python -m spacy download de_core_news_sm\n",
        "!pip install numpy==1.26\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "c2DRfGV-nyG4",
        "outputId": "b615050c-6914-4543-a5e4-fdc99da49afe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Skipping torchaudio as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Skipping torchvision as it is not installed.\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting torchtext==0.16.2\n",
            "  Using cached torchtext-0.16.2-cp311-cp311-manylinux1_x86_64.whl.metadata (7.5 kB)\n",
            "Collecting tqdm (from torchtext==0.16.2)\n",
            "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting requests (from torchtext==0.16.2)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting torch==2.1.2 (from torchtext==0.16.2)\n",
            "  Using cached torch-2.1.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting numpy (from torchtext==0.16.2)\n",
            "  Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "Collecting torchdata==0.7.1 (from torchtext==0.16.2)\n",
            "  Using cached torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n",
            "Collecting filelock (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting urllib3>=1.25 (from torchdata==0.7.1->torchtext==0.16.2)\n",
            "  Using cached urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.9.41-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->torchtext==0.16.2)\n",
            "  Using cached charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests->torchtext==0.16.2)\n",
            "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests->torchtext==0.16.2)\n",
            "  Using cached certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch==2.1.2->torchtext==0.16.2)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Using cached torchtext-0.16.2-cp311-cp311-manylinux1_x86_64.whl (2.0 MB)\n",
            "Using cached torch-2.1.2-cp311-cp311-manylinux1_x86_64.whl (670.2 MB)\n",
            "Using cached torchdata-0.7.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "Using cached numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "Using cached certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "Using cached charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
            "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Using cached urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "Using cached typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "Using cached MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Using cached nvidia_nvjitlink_cu12-12.9.41-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.7 MB)\n",
            "Installing collected packages: mpmath, urllib3, typing-extensions, tqdm, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, triton, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, nvidia-cusolver-cu12, torch, torchdata, torchtext\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.4.0\n",
            "    Uninstalling urllib3-2.4.0:\n",
            "      Successfully uninstalled urllib3-2.4.0\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.13.2\n",
            "    Uninstalling typing_extensions-4.13.2:\n",
            "      Successfully uninstalled typing_extensions-4.13.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
            "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.18.1\n",
            "    Uninstalling nvidia-nccl-cu12-2.18.1:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.18.1\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
            "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
            "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.18.0\n",
            "    Uninstalling filelock-3.18.0:\n",
            "      Successfully uninstalled filelock-3.18.0\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.2\n",
            "    Uninstalling charset-normalizer-3.4.2:\n",
            "      Successfully uninstalled charset-normalizer-3.4.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.4.26\n",
            "    Uninstalling certifi-2025.4.26:\n",
            "      Successfully uninstalled certifi-2025.4.26\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
            "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
            "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
            "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.2\n",
            "    Uninstalling torch-2.1.2:\n",
            "      Successfully uninstalled torch-2.1.2\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.7.1\n",
            "    Uninstalling torchdata-0.7.1:\n",
            "      Successfully uninstalled torchdata-0.7.1\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.16.2\n",
            "    Uninstalling torchtext-0.16.2:\n",
            "      Successfully uninstalled torchtext-0.16.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "timm 1.0.15 requires torchvision, which is not installed.\n",
            "fastai 2.7.19 requires torchvision>=0.11, which is not installed.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.5 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 certifi-2025.4.26 charset-normalizer-3.4.2 filelock-3.18.0 fsspec-2025.3.2 idna-3.10 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.5 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.9.41 nvidia-nvtx-cu12-12.1.105 requests-2.32.3 sympy-1.14.0 torch-2.1.2 torchdata-0.7.1 torchtext-0.16.2 tqdm-4.67.1 triton-2.1.0 typing-extensions-4.13.2 urllib3-2.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "certifi",
                  "charset_normalizer",
                  "markupsafe",
                  "mpmath",
                  "requests",
                  "sympy",
                  "torch",
                  "torchdata",
                  "torchgen",
                  "torchtext",
                  "tqdm"
                ]
              },
              "id": "efdd0ff9d04741108b49cb4279e4bbd8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 148, in _get_module_details\n",
            "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/__init__.py\", line 6, in <module>\n",
            "    from .errors import setup_default_warnings\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/errors.py\", line 3, in <module>\n",
            "    from .compat import Literal\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/compat.py\", line 4, in <module>\n",
            "    from thinc.util import copy_array\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/__init__.py\", line 5, in <module>\n",
            "    from .config import registry\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/config.py\", line 5, in <module>\n",
            "    from .types import Decorator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/types.py\", line 27, in <module>\n",
            "    from .compat import cupy, has_cupy\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/compat.py\", line 35, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1382, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 7, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "Collecting en-core-web-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.2.5 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 189, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 148, in _get_module_details\n",
            "  File \"<frozen runpy>\", line 112, in _get_module_details\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/__init__.py\", line 6, in <module>\n",
            "    from .errors import setup_default_warnings\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/errors.py\", line 3, in <module>\n",
            "    from .compat import Literal\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/spacy/compat.py\", line 4, in <module>\n",
            "    from thinc.util import copy_array\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/__init__.py\", line 5, in <module>\n",
            "    from .config import registry\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/config.py\", line 5, in <module>\n",
            "    from .types import Decorator\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/types.py\", line 27, in <module>\n",
            "    from .compat import cupy, has_cupy\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/thinc/compat.py\", line 35, in <module>\n",
            "    import torch\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/__init__.py\", line 1382, in <module>\n",
            "    from .functional import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/functional.py\", line 7, in <module>\n",
            "    import torch.nn.functional as F\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/__init__.py\", line 1, in <module>\n",
            "    from .modules import *  # noqa: F403\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
            "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
            "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
            "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
            "Collecting de-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.8.0/de_core_news_sm-3.8.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting numpy==1.26\n",
            "  Downloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.5/58.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.2.5\n",
            "    Uninstalling numpy-2.2.5:\n",
            "      Successfully uninstalled numpy-2.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torchvision>=0.11, which is not installed.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from os.path import exists\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import log_softmax\n",
        "import math\n",
        "import copy\n",
        "import time\n",
        "from torch.utils.data import DataLoader\n",
        "import spacy\n",
        "import warnings\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "# Set to False to skip notebook execution (e.g. for debugging)\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "RUN_EXAMPLES = True"
      ],
      "metadata": {
        "id": "19_RLM_39Vk8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Model Architecture"
      ],
      "metadata": {
        "id": "GGPNygrg28AO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Embedding (5pt)\n",
        "\n",
        "Defines the word-embedding layer that maps token indices to dense vectors.\n",
        "\n",
        "The shape of the Embedding should be: **[Vocab, Embedding_size]**"
      ],
      "metadata": {
        "id": "av_WHKp6CayD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(nn.Module):\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super(Embeddings, self).__init__()\n",
        "        ######### add your code here\n",
        "        self.emb =  nn.Embedding(vocab, d_model)\n",
        "        #########\n",
        "        self.d_model = d_model\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.emb(x) * math.sqrt(self.d_model)"
      ],
      "metadata": {
        "id": "3Ikf1cvYCbVQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Position Encoding (15pt)\n",
        "\n",
        "Implements sinusoidal positional encodings so the model can attend to token order without recurrence.\n",
        "\n",
        "$$\n",
        "PE_{(pos, 2i)} = sin(pos/10000^{2i/d_{model}}) \\\\\n",
        "PE_{(pos, 2i+1)} = cos(pos/10000^{2i/d_{model}})\n",
        "$$\n",
        "\n",
        "1. `pos` is the position `i` is the dimension.\n",
        "2. Each dimension of the position encoding corresponds to a sinusoid.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LCqKUlcZCfOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    \"Implement the PE function.\"\n",
        "\n",
        "    def __init__(self, d_model, dropout, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # Compute the positional encodings once in log space.\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len).unsqueeze(1)\n",
        "        ######### add your code here\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, d_model, 2) * -(math.log(10000.0) / d_model)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        #########\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, : x.size(1)].requires_grad_(False)\n",
        "        return self.dropout(x)"
      ],
      "metadata": {
        "id": "EuTdaT08CfUZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 LayerNorm (10pt)\n",
        "Provides a custom Layer Normalization module to stabilise training by normalising hidden states across features.\n",
        "\n",
        "We will follow the basic setting in [Pytorch](https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html).\n",
        "\n",
        "$$\n",
        "y = \\frac{x - E[x]}{Var[x] + \\epsilon}*\\gamma + \\beta\n",
        "$$\n",
        "\n",
        "where:\n",
        "1. `ϵ`: a value added to the denominator for numerical stability\n",
        "2. `γ` & `β`: weight (initialized to 1) and bias (initalized to 0)."
      ],
      "metadata": {
        "id": "lfornq-8_jrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    \"Construct a layernorm module.\"\n",
        "\n",
        "    def __init__(self, features, eps=1e-6):\n",
        "        super(LayerNorm, self).__init__()\n",
        "        ######### add your code here\n",
        "        self.a_2 = nn.Parameter(torch.ones(features))\n",
        "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
        "        #########\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(-1, keepdim=True)\n",
        "        std = x.std(-1, keepdim=True)\n",
        "        ######### add your code here\n",
        "        result = self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n",
        "        #########\n",
        "        return result"
      ],
      "metadata": {
        "id": "Pukl4c0j_njP"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 SubLayer Connection (10pt)\n",
        "\n",
        "Wraps a residual connection around a sub-layer (e.g., attention or FFN). Right here, we apply the pre-norm setup.\n",
        "\n",
        "The output of each sub-layer is:\n",
        "$$\n",
        "x + Sublayer(LayerNorm(x))\n",
        "$$\n",
        "where:\n",
        "1. `Sublayer(x)` is the function implemented by the sub-layer itself.(Attn/MLP)"
      ],
      "metadata": {
        "id": "pUoz2hQ6AG9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SublayerConnection(nn.Module):\n",
        "    \"\"\"\n",
        "    A residual connection followed by a layer norm.\n",
        "    Note for code simplicity the norm is first as opposed to last.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, size, dropout):\n",
        "        super(SublayerConnection, self).__init__()\n",
        "        self.norm = LayerNorm(size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, sublayer):\n",
        "        \"Apply residual connection to any sublayer with the same size.\"\n",
        "        ######### add your code here\n",
        "        return x + self.dropout(sublayer(self.norm(x)))\n",
        "        #########"
      ],
      "metadata": {
        "id": "9jg9mHK9AHVi"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 Multi-Head Attention (20pt)\n",
        "\n",
        "Implements scaled dot-product self-attention, splits it into h parallel “heads,” and concatenates the results back together.\n",
        "\n",
        "For each head:\n",
        "$$\n",
        "Attention(Q, K, V) = softmax(\\frac{Q K^T}{\\sqrt{d_k}})V\n",
        "$$\n",
        "\n",
        "Multi-Head Attention:\n",
        "$$\n",
        "MultiHead(Q, K, V) = Concat(head_1,\\dots, head_h)W^O \\\\\n",
        "where\\quad head_i=Attention(QW^Q_i, KW^K_i, VW^V_i)\n",
        "$$\n"
      ],
      "metadata": {
        "id": "LtUUG8X9A3xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def attention(query, key, value, mask=None, dropout=None):\n",
        "    \"Compute 'Scaled Dot Product Attention'\"\n",
        "    d_k = query.size(-1)\n",
        "    ######### add your code here\n",
        "    scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n",
        "    #########\n",
        "    if mask is not None:\n",
        "        scores = scores.masked_fill(mask == 0, -1e9)\n",
        "    ######### add your code here\n",
        "    p_attn = scores.softmax(dim=-1)\n",
        "    #########\n",
        "    if dropout is not None:\n",
        "        p_attn = dropout(p_attn)\n",
        "    return torch.matmul(p_attn, value), p_attn"
      ],
      "metadata": {
        "id": "8sVsO2_xAtLY"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadedAttention(nn.Module):\n",
        "    def __init__(self, h, d_model, dropout=0.1):\n",
        "        \"Take in model size and number of heads.\"\n",
        "        super(MultiHeadedAttention, self).__init__()\n",
        "        assert d_model % h == 0\n",
        "        # We assume d_v always equals d_k\n",
        "        self.d_k = d_model // h\n",
        "        self.h = h\n",
        "        self.Wq = nn.Linear(d_model, d_model)\n",
        "        self.Wk = nn.Linear(d_model, d_model)\n",
        "        self.Wv = nn.Linear(d_model, d_model)\n",
        "        self.linears = nn.Linear(d_model, d_model)\n",
        "        self.attn = None\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, query, key, value, mask=None):\n",
        "        if mask is not None:\n",
        "            # Same mask applied to all h heads.\n",
        "            mask = mask.unsqueeze(1)\n",
        "        nbatches = query.size(0)\n",
        "\n",
        "        # 1) Do all the linear projections in batch from d_model => h x d_k\n",
        "        ######### add your code here\n",
        "        query = self.Wq(query).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "        key = self.Wk(key).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "        value = self.Wv(value).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
        "        #########\n",
        "\n",
        "        # 2) Apply attention on all the projected vectors in batch.\n",
        "        x, self.attn = attention(\n",
        "            query, key, value, mask=mask, dropout=self.dropout\n",
        "        )\n",
        "\n",
        "        # 3) \"Concat\" using a view and apply a final linear.\n",
        "        ######### add your code here\n",
        "        x =(x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k))\n",
        "        #########\n",
        "\n",
        "        del query\n",
        "        del key\n",
        "        del value\n",
        "        return self.linears(x)"
      ],
      "metadata": {
        "id": "KKXVrr7EAv3P"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.6 FeedFordward Network (FFN) (5pt)\n",
        "Creates the two-layer position-wise feed-forward network applied after each attention block."
      ],
      "metadata": {
        "id": "yL0oZM8eA-LD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionwiseFeedForward(nn.Module):\n",
        "    \"Implements FFN equation.\"\n",
        "\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super(PositionwiseFeedForward, self).__init__()\n",
        "        self.w_1 = nn.Linear(d_model, d_ff)\n",
        "        ######### add your code here\n",
        "        self.w_2 = nn.Linear(d_ff, d_model)\n",
        "        #########\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.w_2(self.dropout(self.w_1(x).relu()))"
      ],
      "metadata": {
        "id": "_Z_Njzq4A-eo"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Encoder"
      ],
      "metadata": {
        "id": "QOWx1p27-wrY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Encoder Layer\n",
        "\n",
        "Defines a single Encoder block consisting of a Multi-Head Self-Attention layer and an FFN, each wrapped in Add & Norm."
      ],
      "metadata": {
        "id": "SVODKZfa_7rO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
        "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.self_attn = self_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
        "        self.size = size\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
        "        return self.sublayer[1](x, self.feed_forward)"
      ],
      "metadata": {
        "id": "wJWBzFyt-64U"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Encoder Stacks (10pt)\n",
        "Stacks N Encoder blocks to form the full Encoder."
      ],
      "metadata": {
        "id": "eLfbujxM_411"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clones(module, N):\n",
        "    \"Produce N identical layers.\"\n",
        "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "    \"Core encoder is a stack of N layers\"\n",
        "    def __init__(self, layer, N):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        \"Pass the input (and mask) through each layer in turn.\"\n",
        "        ######### add your code here\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, mask)\n",
        "        #########\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "Zp6UtcVC-0El"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Decoder"
      ],
      "metadata": {
        "id": "A-yz1UvNAaD-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Decoder Layer (5pt)\n",
        "\n",
        "Details a single Decoder block containing masked self-attention, cross-attention, and an FFN, each with residual Add & Norm."
      ],
      "metadata": {
        "id": "KxTvioDZAibw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
        "\n",
        "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.size = size\n",
        "        self.self_attn = self_attn\n",
        "        self.src_attn = src_attn\n",
        "        self.feed_forward = feed_forward\n",
        "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        \"Follow Figure 1 (right) for connections.\"\n",
        "        m = memory\n",
        "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
        "        ######### add your code here\n",
        "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
        "        #########\n",
        "        return self.sublayer[2](x, self.feed_forward)"
      ],
      "metadata": {
        "id": "EgWip7SNAkqZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Decoder Stacks (10pt)\n",
        "Stacks N Decoder blocks to build the complete Decoder."
      ],
      "metadata": {
        "id": "naHuN-v8Ae8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"Generic N layer decoder with masking.\"\n",
        "\n",
        "    def __init__(self, layer, N):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.layers = clones(layer, N)\n",
        "        self.norm = LayerNorm(layer.size)\n",
        "\n",
        "    def forward(self, x, memory, src_mask, tgt_mask):\n",
        "        ######### add your code here\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, memory, src_mask, tgt_mask)\n",
        "        #########\n",
        "        return self.norm(x)"
      ],
      "metadata": {
        "id": "abuJsIP5AZbU"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model\n",
        "\n",
        "Combines the Encoder and Decoder into a full Transformer model and adds a linear projection to produce logits over the target vocabulary."
      ],
      "metadata": {
        "id": "gQmMX48iCn0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A standard Encoder-Decoder architecture. Base for this and many\n",
        "    other models.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.tgt_embed = tgt_embed\n",
        "        self.generator = generator\n",
        "\n",
        "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
        "        \"Take in and process masked src and target sequences.\"\n",
        "        return self.decode(self.encode(src, src_mask), src_mask, tgt, tgt_mask)\n",
        "\n",
        "    def encode(self, src, src_mask):\n",
        "        return self.encoder(self.src_embed(src), src_mask)\n",
        "\n",
        "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
        "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    \"Define standard linear + softmax generation step.\"\n",
        "\n",
        "    def __init__(self, d_model, vocab):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(d_model, vocab)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return log_softmax(self.proj(x), dim=-1)"
      ],
      "metadata": {
        "id": "CAlGGs3DCvyL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_model(\n",
        "    src_vocab, tgt_vocab, N=6, d_model=512, d_ff=2048, h=8, dropout=0.1\n",
        "):\n",
        "    \"Helper: Construct a model from hyperparameters.\"\n",
        "    c = copy.deepcopy\n",
        "    attn = MultiHeadedAttention(h, d_model)\n",
        "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
        "    position = PositionalEncoding(d_model, dropout)\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
        "        Decoder(DecoderLayer(d_model, c(attn), c(attn), c(ff), dropout), N),\n",
        "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
        "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
        "        Generator(d_model, tgt_vocab),\n",
        "    )\n",
        "\n",
        "    # This was important from their code.\n",
        "    # Initialize parameters with Glorot / fan_avg.\n",
        "    for p in model.parameters():\n",
        "        if p.dim() > 1:\n",
        "            nn.init.xavier_uniform_(p)\n",
        "    return model"
      ],
      "metadata": {
        "id": "gn3geYnbCpWv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train (10pt)\n",
        "\n",
        "Prepares a small EN→DE dataset, builds dataloaders, defines the loss, optimizer, and training loop, then runs a quick demonstration training epoch followed by an inference example."
      ],
      "metadata": {
        "id": "qFaaJLjmErAr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import time\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "import spacy\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "def subsequent_mask(size, device=None):\n",
        "    # Mask has 1s in the *allowed* (≤ i) positions, 0 elsewhere\n",
        "    attn_shape = (1, size, size)\n",
        "    mask = torch.triu(torch.ones(attn_shape, dtype=torch.bool, device=device), diagonal=1)\n",
        "    return ~mask      # invert so future positions are 0\n",
        "\n",
        "# Load tokenizers (ensure you've downloaded the models:\n",
        "# python -m spacy download en_core_web_sm && python -m spacy download de_core_news_sm)\n",
        "spacy_de = spacy.load('de_core_news_sm')\n",
        "spacy_en = spacy.load('en_core_web_sm')\n",
        "\n",
        "def tokenize_de(text):\n",
        "    return [tok.text.lower() for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "def tokenize_en(text):\n",
        "    return [tok.text.lower() for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "# Prepare dataset (only 500 samples for a quick test)\n",
        "raw_iter = Multi30k(split='train', language_pair=('en', 'de'))\n",
        "raw_data = list(raw_iter)[:500]\n",
        "test_iter = Multi30k(split='valid', language_pair=('en', 'de'))\n",
        "test_data = list(test_iter)[:10]\n",
        "\n",
        "# Build vocabularies with special tokens\n",
        "SRC_SPECIALS = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "TGT_SPECIALS = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
        "\n",
        "vocab_src = build_vocab_from_iterator((tokenize_en(pair[0]) for pair in raw_data), specials=SRC_SPECIALS)\n",
        "vocab_tgt = build_vocab_from_iterator((tokenize_de(pair[1]) for pair in raw_data), specials=TGT_SPECIALS)\n",
        "\n",
        "vocab_src.set_default_index(vocab_src['<unk>'])\n",
        "vocab_tgt.set_default_index(vocab_tgt['<unk>'])\n",
        "\n",
        "SRC_PAD_IDX = vocab_src['<pad>']\n",
        "TGT_PAD_IDX = vocab_tgt['<pad>']\n",
        "\n",
        "def collate_fn(batch):\n",
        "    src_batch, tgt_batch = [], []\n",
        "    for src, tgt in batch:\n",
        "        src_tokens = [vocab_src['<bos>']] + [vocab_src[token] for token in tokenize_en(src)] + [vocab_src['<eos>']]\n",
        "        tgt_tokens = [vocab_tgt['<bos>']] + [vocab_tgt[token] for token in tokenize_de(tgt)] + [vocab_tgt['<eos>']]\n",
        "        src_batch.append(torch.tensor(src_tokens, dtype=torch.long))\n",
        "        tgt_batch.append(torch.tensor(tgt_tokens, dtype=torch.long))\n",
        "    src_batch = pad_sequence(src_batch, padding_value=SRC_PAD_IDX, batch_first=True)\n",
        "    tgt_batch = pad_sequence(tgt_batch, padding_value=TGT_PAD_IDX, batch_first=True)\n",
        "    return src_batch, tgt_batch\n",
        "\n",
        "train_loader = DataLoader(raw_data, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_data, batch_size=2, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = make_model(len(vocab_src), len(vocab_tgt), N=2, d_model=64, d_ff=128, h=4, dropout=0.1).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.NLLLoss(ignore_index=TGT_PAD_IDX)\n",
        "\n",
        "\n",
        "model.train()\n",
        "epochs = 200\n",
        "for epoch in range(epochs):\n",
        "    start_time = time.time()\n",
        "    total_loss = 0\n",
        "    for i, (src, tgt) in enumerate(train_loader):\n",
        "        src, tgt = src.to(device), tgt.to(device)\n",
        "        tgt_input = tgt[:, :-1]\n",
        "        src_mask = (src != SRC_PAD_IDX).unsqueeze(-2)\n",
        "        tgt_pad_mask = (tgt_input != TGT_PAD_IDX).unsqueeze(-2)\n",
        "        tgt_mask     = tgt_pad_mask & subsequent_mask(tgt_input.size(1), device=tgt_input.device)\n",
        "        ######### add your code here\n",
        "        out =  model.forward(src,tgt_input,src_mask,tgt_mask)\n",
        "        #########\n",
        "        logits = model.generator(out)\n",
        "        loss = criterion(logits.reshape(-1, logits.size(-1)), tgt[:, 1:].reshape(-1))\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    print(f\"{STUDENT_NAME} Epoch {epoch} | Loss: {total_loss/(i+1):.4f} | Time: {time.time()-start_time:.2f}s\")"
      ],
      "metadata": {
        "id": "_SU86-VkEuOC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f5de1ff-f94b-42bf-f9f0-b114db2c9cc4"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shubham Derhgawen Epoch 0 | Loss: 7.1366 | Time: 1.33s\n",
            "Shubham Derhgawen Epoch 1 | Loss: 6.9783 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 2 | Loss: 6.8661 | Time: 0.39s\n",
            "Shubham Derhgawen Epoch 3 | Loss: 6.7688 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 4 | Loss: 6.6818 | Time: 0.40s\n",
            "Shubham Derhgawen Epoch 5 | Loss: 6.5923 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 6 | Loss: 6.5028 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 7 | Loss: 6.4126 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 8 | Loss: 6.3214 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 9 | Loss: 6.2348 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 10 | Loss: 6.1479 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 11 | Loss: 6.0613 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 12 | Loss: 5.9798 | Time: 0.39s\n",
            "Shubham Derhgawen Epoch 13 | Loss: 5.8950 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 14 | Loss: 5.8178 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 15 | Loss: 5.7483 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 16 | Loss: 5.6743 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 17 | Loss: 5.6099 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 18 | Loss: 5.5493 | Time: 0.66s\n",
            "Shubham Derhgawen Epoch 19 | Loss: 5.4917 | Time: 0.47s\n",
            "Shubham Derhgawen Epoch 20 | Loss: 5.4401 | Time: 0.75s\n",
            "Shubham Derhgawen Epoch 21 | Loss: 5.3886 | Time: 1.05s\n",
            "Shubham Derhgawen Epoch 22 | Loss: 5.3422 | Time: 0.55s\n",
            "Shubham Derhgawen Epoch 23 | Loss: 5.2985 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 24 | Loss: 5.2516 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 25 | Loss: 5.2080 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 26 | Loss: 5.1726 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 27 | Loss: 5.1363 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 28 | Loss: 5.1038 | Time: 0.39s\n",
            "Shubham Derhgawen Epoch 29 | Loss: 5.0652 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 30 | Loss: 5.0275 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 31 | Loss: 4.9947 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 32 | Loss: 4.9598 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 33 | Loss: 4.9255 | Time: 0.40s\n",
            "Shubham Derhgawen Epoch 34 | Loss: 4.8965 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 35 | Loss: 4.8568 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 36 | Loss: 4.8227 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 37 | Loss: 4.7937 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 38 | Loss: 4.7503 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 39 | Loss: 4.7198 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 40 | Loss: 4.6871 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 41 | Loss: 4.6518 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 42 | Loss: 4.6245 | Time: 0.55s\n",
            "Shubham Derhgawen Epoch 43 | Loss: 4.5783 | Time: 0.50s\n",
            "Shubham Derhgawen Epoch 44 | Loss: 4.5548 | Time: 0.54s\n",
            "Shubham Derhgawen Epoch 45 | Loss: 4.5248 | Time: 0.54s\n",
            "Shubham Derhgawen Epoch 46 | Loss: 4.4854 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 47 | Loss: 4.4506 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 48 | Loss: 4.4283 | Time: 0.51s\n",
            "Shubham Derhgawen Epoch 49 | Loss: 4.3910 | Time: 0.49s\n",
            "Shubham Derhgawen Epoch 50 | Loss: 4.3604 | Time: 0.48s\n",
            "Shubham Derhgawen Epoch 51 | Loss: 4.3334 | Time: 0.58s\n",
            "Shubham Derhgawen Epoch 52 | Loss: 4.2952 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 53 | Loss: 4.2689 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 54 | Loss: 4.2476 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 55 | Loss: 4.2169 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 56 | Loss: 4.1905 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 57 | Loss: 4.1672 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 58 | Loss: 4.1364 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 59 | Loss: 4.1138 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 60 | Loss: 4.0943 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 61 | Loss: 4.0593 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 62 | Loss: 4.0381 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 63 | Loss: 4.0183 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 64 | Loss: 4.0038 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 65 | Loss: 3.9761 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 66 | Loss: 3.9469 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 67 | Loss: 3.9212 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 68 | Loss: 3.9040 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 69 | Loss: 3.8882 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 70 | Loss: 3.8696 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 71 | Loss: 3.8434 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 72 | Loss: 3.8288 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 73 | Loss: 3.8016 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 74 | Loss: 3.7906 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 75 | Loss: 3.7776 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 76 | Loss: 3.7521 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 77 | Loss: 3.7299 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 78 | Loss: 3.7223 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 79 | Loss: 3.6933 | Time: 0.50s\n",
            "Shubham Derhgawen Epoch 80 | Loss: 3.6800 | Time: 0.52s\n",
            "Shubham Derhgawen Epoch 81 | Loss: 3.6672 | Time: 0.48s\n",
            "Shubham Derhgawen Epoch 82 | Loss: 3.6432 | Time: 0.58s\n",
            "Shubham Derhgawen Epoch 83 | Loss: 3.6308 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 84 | Loss: 3.6099 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 85 | Loss: 3.5997 | Time: 0.41s\n",
            "Shubham Derhgawen Epoch 86 | Loss: 3.5811 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 87 | Loss: 3.5741 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 88 | Loss: 3.5502 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 89 | Loss: 3.5362 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 90 | Loss: 3.5144 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 91 | Loss: 3.5021 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 92 | Loss: 3.4938 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 93 | Loss: 3.4746 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 94 | Loss: 3.4586 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 95 | Loss: 3.4492 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 96 | Loss: 3.4351 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 97 | Loss: 3.4219 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 98 | Loss: 3.4058 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 99 | Loss: 3.3878 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 100 | Loss: 3.3772 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 101 | Loss: 3.3601 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 102 | Loss: 3.3481 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 103 | Loss: 3.3362 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 104 | Loss: 3.3157 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 105 | Loss: 3.3008 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 106 | Loss: 3.2936 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 107 | Loss: 3.2825 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 108 | Loss: 3.2565 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 109 | Loss: 3.2488 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 110 | Loss: 3.2370 | Time: 0.54s\n",
            "Shubham Derhgawen Epoch 111 | Loss: 3.2236 | Time: 0.50s\n",
            "Shubham Derhgawen Epoch 112 | Loss: 3.2166 | Time: 0.53s\n",
            "Shubham Derhgawen Epoch 113 | Loss: 3.1978 | Time: 0.57s\n",
            "Shubham Derhgawen Epoch 114 | Loss: 3.1964 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 115 | Loss: 3.1728 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 116 | Loss: 3.1569 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 117 | Loss: 3.1456 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 118 | Loss: 3.1341 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 119 | Loss: 3.1299 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 120 | Loss: 3.1026 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 121 | Loss: 3.0899 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 122 | Loss: 3.0827 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 123 | Loss: 3.0677 | Time: 0.39s\n",
            "Shubham Derhgawen Epoch 124 | Loss: 3.0529 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 125 | Loss: 3.0409 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 126 | Loss: 3.0447 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 127 | Loss: 3.0207 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 128 | Loss: 3.0093 | Time: 0.39s\n",
            "Shubham Derhgawen Epoch 129 | Loss: 2.9988 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 130 | Loss: 2.9843 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 131 | Loss: 2.9613 | Time: 0.39s\n",
            "Shubham Derhgawen Epoch 132 | Loss: 2.9532 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 133 | Loss: 2.9456 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 134 | Loss: 2.9296 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 135 | Loss: 2.9223 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 136 | Loss: 2.9032 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 137 | Loss: 2.8926 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 138 | Loss: 2.8824 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 139 | Loss: 2.8730 | Time: 0.39s\n",
            "Shubham Derhgawen Epoch 140 | Loss: 2.8633 | Time: 0.43s\n",
            "Shubham Derhgawen Epoch 141 | Loss: 2.8442 | Time: 0.54s\n",
            "Shubham Derhgawen Epoch 142 | Loss: 2.8318 | Time: 0.48s\n",
            "Shubham Derhgawen Epoch 143 | Loss: 2.8270 | Time: 0.55s\n",
            "Shubham Derhgawen Epoch 144 | Loss: 2.8118 | Time: 0.48s\n",
            "Shubham Derhgawen Epoch 145 | Loss: 2.7899 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 146 | Loss: 2.7929 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 147 | Loss: 2.7749 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 148 | Loss: 2.7688 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 149 | Loss: 2.7493 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 150 | Loss: 2.7316 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 151 | Loss: 2.7311 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 152 | Loss: 2.7168 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 153 | Loss: 2.7025 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 154 | Loss: 2.6946 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 155 | Loss: 2.6784 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 156 | Loss: 2.6717 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 157 | Loss: 2.6594 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 158 | Loss: 2.6416 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 159 | Loss: 2.6455 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 160 | Loss: 2.6195 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 161 | Loss: 2.6075 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 162 | Loss: 2.5935 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 163 | Loss: 2.5935 | Time: 0.40s\n",
            "Shubham Derhgawen Epoch 164 | Loss: 2.5722 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 165 | Loss: 2.5647 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 166 | Loss: 2.5568 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 167 | Loss: 2.5448 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 168 | Loss: 2.5379 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 169 | Loss: 2.5187 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 170 | Loss: 2.5114 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 171 | Loss: 2.5008 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 172 | Loss: 2.4893 | Time: 0.50s\n",
            "Shubham Derhgawen Epoch 173 | Loss: 2.4821 | Time: 0.48s\n",
            "Shubham Derhgawen Epoch 174 | Loss: 2.4593 | Time: 0.47s\n",
            "Shubham Derhgawen Epoch 175 | Loss: 2.4607 | Time: 0.54s\n",
            "Shubham Derhgawen Epoch 176 | Loss: 2.4554 | Time: 0.43s\n",
            "Shubham Derhgawen Epoch 177 | Loss: 2.4371 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 178 | Loss: 2.4345 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 179 | Loss: 2.4196 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 180 | Loss: 2.4034 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 181 | Loss: 2.3949 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 182 | Loss: 2.3791 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 183 | Loss: 2.3726 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 184 | Loss: 2.3629 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 185 | Loss: 2.3465 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 186 | Loss: 2.3471 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 187 | Loss: 2.3216 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 188 | Loss: 2.3142 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 189 | Loss: 2.3083 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 190 | Loss: 2.3029 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 191 | Loss: 2.2865 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 192 | Loss: 2.2820 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 193 | Loss: 2.2682 | Time: 0.39s\n",
            "Shubham Derhgawen Epoch 194 | Loss: 2.2491 | Time: 0.35s\n",
            "Shubham Derhgawen Epoch 195 | Loss: 2.2511 | Time: 0.36s\n",
            "Shubham Derhgawen Epoch 196 | Loss: 2.2406 | Time: 0.38s\n",
            "Shubham Derhgawen Epoch 197 | Loss: 2.2255 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 198 | Loss: 2.2231 | Time: 0.37s\n",
            "Shubham Derhgawen Epoch 199 | Loss: 2.2044 | Time: 0.36s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "2IYPYTNoa0KN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Greedy decoding for inference\n",
        "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
        "    memory = model.encode(src, src_mask)\n",
        "    ys = torch.ones(1, 1, dtype=torch.long).fill_(start_symbol).to(device)\n",
        "    for _ in range(max_len - 1):\n",
        "        tgt_mask = subsequent_mask(ys.size(1)).to(device)\n",
        "        out = model.decode(memory, src_mask, ys, tgt_mask)\n",
        "        prob = model.generator(out[:, -1])\n",
        "        next_word = torch.argmax(prob, dim=1).item()\n",
        "        ys = torch.cat([ys, torch.tensor([[next_word]], dtype=torch.long).to(device)], dim=1)\n",
        "        if next_word == vocab_tgt['<eos>']:\n",
        "            break\n",
        "    return ys\n",
        "\n",
        "model.eval()\n",
        "for index, example in enumerate(test_data[:10]):\n",
        "    src = torch.tensor(\n",
        "        [vocab_src['<bos>']] + [vocab_src[t] for t in tokenize_en(example[0])] + [vocab_src['<eos>']],\n",
        "        dtype=torch.long\n",
        "    ).unsqueeze(0).to(device)\n",
        "    src_mask = (src != SRC_PAD_IDX).unsqueeze(-2)\n",
        "    translation = greedy_decode(model, src, src_mask, max_len=50, start_symbol=vocab_tgt['<bos>'])\n",
        "    tokens = [vocab_tgt.get_itos()[idx] for idx in translation.squeeze().tolist()]\n",
        "\n",
        "    print(\"Source:\", example[0])\n",
        "    print(\"Reference:\", example[1])\n",
        "    print(\"Predicted:\", \" \".join(tokens))\n",
        "    print('*******'*50)"
      ],
      "metadata": {
        "id": "4eXzi_Kaa0Uf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2d6e8d0-145c-4c1e-c701-cf4d99b5b60a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source: A group of men are loading cotton onto a truck\n",
            "Reference: Eine Gruppe von Männern lädt Baumwolle auf einen Lastwagen\n",
            "Predicted: <bos> eine frau in einem geländer straße auf einem gleis . <eos>\n",
            "**************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
            "Source: A man sleeping in a green room on a couch.\n",
            "Reference: Ein Mann schläft in einem grünen Raum auf einem Sofa.\n",
            "Predicted: <bos> ein mann , der in einer roten oberteil und sich . <eos>\n",
            "**************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
            "Source: A boy wearing headphones sits on a woman's shoulders.\n",
            "Reference: Ein Junge mit Kopfhörern sitzt auf den Schultern einer Frau.\n",
            "Predicted: <bos> ein junge mit einem roten hemd und eine frau . <eos>\n",
            "**************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
            "Source: Two men setting up a blue ice fishing hut on an iced over lake\n",
            "Reference: Zwei Männer bauen eine blaue Eisfischerhütte auf einem zugefrorenen See auf\n",
            "Predicted: <bos> zwei männer stehen in einer wiese und eine frau , die auf einer wiese . <eos>\n",
            "**************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
            "Source: A balding man wearing a red life jacket is sitting in a small boat.\n",
            "Reference: Ein Mann mit beginnender Glatze, der eine rote Rettungsweste trägt, sitzt in einem kleinen Boot.\n",
            "Predicted: <bos> ein mann in einem roten hemd , der in einem roten hemd , in einem weißen hemd . <eos>\n",
            "**************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
            "Source: A lady in a red coat, holding a bluish hand bag likely of asian descent, jumping off the ground for a snapshot.\n",
            "Reference: Eine Frau in einem rotem Mantel, die eine vermutlich aus Asien stammende Handtasche in einem blauen Farbton hält, springt für einen Schnappschuss in die Luft.\n",
            "Predicted: <bos> eine frau in einem roten hemd , die in einem grünen , während ein anderer , während ein gelbes hemd trägt . <eos>\n",
            "**************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
            "Source: A brown dog is running after the black dog.\n",
            "Reference: Ein brauner Hund rennt dem schwarzen Hund hinterher.\n",
            "Predicted: <bos> ein hund rennt durch ein hund . <eos>\n",
            "**************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
            "Source: A young boy wearing a Giants jersey swings a baseball bat at an incoming pitch.\n",
            "Reference: Ein kleiner Junge mit einem Giants-Trikot schwingt einen Baseballschläger in Richtung eines ankommenden Balls.\n",
            "Predicted: <bos> ein junge in einem roten hemd sitzt auf einer bank . <eos>\n",
            "**************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
            "Source: A man in a cluttered office is using the telephone\n",
            "Reference: Ein Mann telefoniert in einem unaufgeräumten Büro\n",
            "Predicted: <bos> ein mann in einer bank , der auf einer wiese . <eos>\n",
            "**************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n",
            "Source: A smiling woman in a peach tank top stands holding a mountain bike\n",
            "Reference: Eine lächelnde Frau mit einem pfirsichfarbenen Trägershirt hält ein Mountainbike\n",
            "Predicted: <bos> eine frau , die eine frau , die eine frau , die auf einem weißen hand . <eos>\n",
            "**************************************************************************************************************************************************************************************************************************************************************************************************************************************************************\n"
          ]
        }
      ]
    }
  ]
}